[ { "title": "How I Only Spend 30 Minutes a Month to Run My Rust Server", "url": "/posts/bash-scripting/", "categories": "Linux, Game Servers", "tags": "Bash, Cron, At, Scripting, Automation, Linux, Rust", "date": "2024-10-11 09:00:00 -0700", "snippet": "IntroductionRunning a Rust game server can be a complex and time consuming, but with the power of Bash scripting and Linux scheduling tools like Cron and At, we can automate many aspects of server management. In this post, we’ll explore how to use these tools to make running your Rust server easier and more efficient.Use Bash to its Fullest PotentialBash is the default command-line interface for most Linux distributions. For Rust server management, it allows us to create scripts for common tasks. Let’s start with a simple example:#!/bin/bash# Start the Rust serverstart_server() { echo &quot;Starting Rust server...&quot; /path/to/rustserver start}# Stop the Rust serverstop_server() { echo &quot;Stopping Rust server...&quot; /path/to/rustserver stop}# Restart the Rust serverrestart_server() { stop_server sleep 5 # Wait for 5 seconds start_server}# Check server statusserver_status() { echo &quot;Checking server status...&quot; /path/to/rustserver status}# Main script logiccase &quot;$1&quot; in start) start_server ;; stop) stop_server ;; restart) restart_server ;; status) server_status ;; *) echo &quot;Usage: $0 {start|stop|restart|status}&quot; ;;esacSave this as rust_server.sh, make it executable with chmod +x rust_server.sh, and you can now easily manage your server with commands like ./rust_server.sh start or ./rust_server.sh restart.Automating Server Tasks with CronCron allows us to schedule recurring tasks. Here are some useful automations for a Rust server:Regular Server RestartsTo restart your server daily at 4:00 AM:0 4 * * * /path/to/rust_server.sh restartAdd this line to your crontab by running crontab -e.Automatic BackupsCreate a backup script:#!/bin/bashBACKUP_DIR=&quot;/path/to/backups&quot;SERVER_DIR=&quot;/path/to/rust_server&quot;# Create timestampTIMESTAMP=$(date +&quot;%Y%m%d_%H%M%S&quot;)# Stop the server/path/to/rust_server.sh stop# Create backuptar -czf &quot;$BACKUP_DIR/rust_backup_$TIMESTAMP.tar.gz&quot; -C &quot;$SERVER_DIR&quot; .# Start the server/path/to/rust_server.sh startecho &quot;Backup completed: rust_backup_$TIMESTAMP.tar.gz&quot;Save this as rust_backup.sh and make it executable. Then, to run it every day at 3:00 AM:0 3 * * * /path/to/rust_backup.shServer UpdatesFor automatic updates, create an update script:#!/bin/bash# Stop the server/path/to/rust_server.sh stop# Update the server/path/to/steamcmd +login anonymous +force_install_dir /path/to/rust_server +app_update 258550 validate +quit# Start the server/path/to/rust_server.sh startecho &quot;Server update completed&quot;Save this as rust_update.sh, make it executable, and schedule it weekly:0 2 * * 1 /path/to/rust_update.sh # Runs every Monday at 2:00 AMUsing At for One-time TasksAt is useful for scheduling one-time tasks. For example, to schedule a server restart in 2 hours:echo &quot;/path/to/rust_server.sh restart&quot; | at now + 2 hoursThis is handy for scheduling maintenance after notifying players.Advanced Automation: Server Monitoring and AlertsLet’s create a script to monitor server health and send alerts:#!/bin/bash# Check if server is runningif ! pgrep -f rustserver &amp;gt; /dev/nullthen echo &quot;Rust server is down! Attempting to restart...&quot; /path/to/rust_server.sh restart # Send alert (replace with your preferred method) echo &quot;Rust server was down and has been restarted&quot; | mail -s &quot;Server Alert&quot; your@email.comfi# Check server resourcesCPU_USAGE=$(top -bn1 | grep &quot;Cpu(s)&quot; | sed &quot;s/.*, *\\([0-9.]*\\)%* id.*/\\1/&quot; | awk &#39;{print 100 - $1}&#39;)MEM_USAGE=$(free | grep Mem | awk &#39;{print $3/$2 * 100.0}&#39;)if (( $(echo &quot;$CPU_USAGE &amp;gt; 90&quot; | bc -l) )) || (( $(echo &quot;$MEM_USAGE &amp;gt; 90&quot; | bc -l) ))then echo &quot;High resource usage detected! CPU: $CPU_USAGE%, Memory: $MEM_USAGE%&quot; | mail -s &quot;Server Resource Alert&quot; your@email.comfiSave this as monitor_rust.sh, make it executable, and run it every 5 minutes with cron:*/5 * * * * /path/to/monitor_rust.shConclusionBy leveraging Bash scripting along with Cron and At, we’ve automated several key aspects of managing a Rust game server: Basic server management (start, stop, restart) Scheduled restarts Automatic backups Server updates Health monitoring and alertsThese automations can significantly reduce the manual work involved in server management, ensure your server stays up-to-date and running smoothly, and quickly alert you to any issues.Remember to test your scripts thoroughly in a safe environment before deploying them on a live server. As you become more comfortable with these tools, you can create more complex automations tailored to your specific needs.Happy server managing!" }, { "title": "How to Set Up an AD Domain (Video Demonstration)", "url": "/posts/active-directory-home-lab/", "categories": "Guides, Homelab, Active Directory", "tags": "Instructional, Guides, Networking, Active Directory, DHCP, DNS, RAS, NAT, Domain, Powershell, Windows 10, Windows Server", "date": "2023-03-21 08:24:00 -0700", "snippet": " DescriptionFor this guide I thought it would be best to demonstrate how to set up Active Directory with a video as trying to do so with a blogpost would make it very hard to follow along. Making it in a video form also allows me to more effectively explain many of the concepts that goes into creating a domain controller by explaining it visually via drawing tools. I hope you enjoy the video.TimestampsInstalling Windows 2019 Server on VirtualBox 1:17 - 10:00Configuring Network Adapters 10:10 - 12:54Configuring the Domain Controller 12:58 - 24:22Configuring Network Address Translation 25:15 - 28:48Configuring DHCP Server 31:00 - 35:13Creating Users w/ Powershell 35:24 - 51:29Creating a Windows 10 Client on VirtualBox 52:38 - 59:20LinksOracle VirtualBoxServer 2019 ISOWindows 10 ISORandom Name GeneratorScript Used in the Video$PASSWORD = &quot;Password1&quot;$USER_NAMES = Get-Content .\\names.txt$ENCRYPTED_PASSWORD = ConvertTo-SecureString $PASSWORD -AsPlainText -ForceNew-ADOrganizationalUnit -Name _USERS -ProtectedFromAccidentalDeletion $falseforeach ($n in $USER_NAMES) { $first = $n.Split(&quot; &quot;)[0].ToLower() $last = $n.Split(&quot; &quot;)[1].ToLower() $username = &quot;$($first.Substring(0,1))$($last)&quot;.ToLower() Write-Host &quot;Creating User: $($username)&quot; -BackgroundColor Black -ForegroundColor Cyan New-AdUser -AccountPassword $ENCRYPTED_PASSWORD ` -GivenName $first ` -Surname $last ` -DisplayName $username ` -Name $username ` -EmployeeID $username ` -PasswordNeverExpires $true ` -Path &quot;ou=_USERS,$(([ADSI]`&quot;&quot;).distinguishedName)&quot; ` -Enabled $true}" }, { "title": "How I Learned to Stop Worrying and Love ChatGPT", "url": "/posts/love-chatgpt/", "categories": "Blogging, Tech", "tags": "Blogging, News, Tech, AI, ChatGPT, Career, Automation", "date": "2023-02-22 10:51:00 -0800", "snippet": "The header image is generated by Midjourney and this blogpost is partially written by ChatGPTIntroductionThe rapid evolution of AI, particularly ChatGPT, has been both fascinating and slightly unsettling to witness. Like many in the tech world, I’ve gone from skepticism to cautious optimism, and I wanted to share my thoughts on this journey.The Early Days: ChatGPT-2When ChatGPT-2 first appeared, it was more of a novelty than a tool. Its responses were often erroneous or nonsensical, leading to amusing exchanges rather than productive ones. While it showed promise, it was hard to take seriously as a practical application of AI.The Leap Forward: ChatGPT-3 and 3.5The release of ChatGPT-3 and 3.5 marked a significant shift. Suddenly, the potential of this technology became clear. Its ability to understand context, generate coherent responses, and even assist with coding tasks was remarkable.What struck me was its versatility. From drafting cover letters to composing poetry, the applications seemed endless. I found myself using it to brainstorm ideas for blog posts and to help with complex coding problems.A colleague at my sister’s tax firm began using it to generate Excel algorithms, streamlining their workflow. Even more surprisingly, a friend found success using it to craft engaging messages on dating apps. These real-world applications highlighted how AI could augment human capabilities in unexpected ways.The Dark Side: Potential MisusesLike with any tool, there are good uses and bad uses. While the use of ChatGPT has opened up a world of possibilities in terms of its applications, there are also negative effects that come with its use.One of the biggest concerns is the potential for deception and misinformation to be automated and targeted towards individuals. With the advent of AI and the ability to generate language that is indistinguishable from human language, it has become easier than ever to create fake content. This can have negative implications on society, as people may be more likely to trust information that is presented to them by a natural language model that will be indistinguishable from a real person, even if it is completely fabricated.Furthermore, the ease with which misinformation and fake content can be disseminated via social media and other platforms has made it easier for bad actors to target specific individuals with false information. This can have serious consequences in terms of influencing people’s beliefs and actions, and can ultimately lead to harm.Overall, while the use of ChatGPT can have many positive applications, it is important to be aware of its negative effects and to take steps to mitigate these risks. As society becomes more reliant on AI and machine learning, it will be important to carefully consider the implications of these technologies and to develop ethical frameworks to guide their use.ChatGPT and the Future of AIAs artificial intelligence continues to develop and evolve, it is clear that it will have a significant impact on the future. One of the most significant effects will be on the workforce, as automation and AI technologies replace many jobs that were previously done by humans. While it is unlikely that ChatGPT will replace most white-collar jobs, it will certainly augment our productivity and change the nature of work. This will require workers to adapt and learn new skills to remain relevant in the job market.Another potential impact of AI is on authenticity and sincerity. According to studies, people view you as less authentic and sincere if they know you used an AI to help you with a task such as writing a cover letter or composing a message. This raises important questions about the nature of authenticity and whether AI-generated content can truly reflect the intentions and personality of the user.It is also important to recognize that AI is still an imperfect technology and will make mistakes. It will be confident in its answers, even when it is wrong, and it will require human oversight and input to ensure that it is used effectively and responsibly. As with any tool, it is up to the user to decide how to use it, whether for good or for bad.In the long term, the impact of AI on society will depend on how it is developed and used. As AI technologies continue to advance, it is crucial that they are used ethically and responsibly. This means that developers must consider the potential consequences of their work and ensure that AI is used to benefit society as a whole. While there are certainly risks and challenges associated with the development of AI, there is also enormous potential for positive change, and it is up to us to ensure that this potential is realized.Will We Be Replaced By AI?The question of whether AI will replace humans is complex and nuanced. It’s a concern that has been amplified by media portrayals and sci-fi narratives, but the reality is likely to be far more subtle.In my experience working with AI tools like ChatGPT, I’ve come to see them more as powerful augmentations to human capabilities rather than replacements. These tools can process vast amounts of data and identify patterns far more quickly than humans, potentially accelerating scientific progress and enabling more informed decision-making in fields like finance, medicine, and transportation.However, AI still lacks the creativity, emotional intelligence, and complex reasoning that humans possess. It’s excellent at tasks involving pattern recognition and data processing, but struggles with nuanced interpretation, ethical decision-making, and generating truly original ideas.That said, AI will undoubtedly change the nature of work. Routine, repetitive tasks are likely to be automated, requiring many of us to adapt and focus on skills that AI can’t easily replicate. This shift may free up more time for creative and strategic thinking, potentially leading to new types of jobs we haven’t even imagined yet.The key to navigating this future lies in how we develop and implement AI technologies. Ethical considerations must be at the forefront, ensuring that AI is used to benefit society as a whole rather than exacerbate existing inequalities.Personally, I believe that our goal should be to create a symbiotic relationship with AI, where we leverage its strengths to enhance our own capabilities. By doing so, we can potentially solve complex global challenges and push the boundaries of human knowledge and achievement.The future isn’t about humans versus AI, but rather humans and AI working together. Our task is to shape this future responsibly, ensuring that AI remains a tool that enhances human potential rather than diminishes it.How I Use ChatGPT and How You Can Use ItChatGPT has proven to be a powerful tool for a variety of tasks, including helping with technical writing and creative endeavors. I personally have found it to be a valuable resource for several different projects. For example, I have used it to help me write PowerShell and Bash scripts, allowing me to automate certain tasks and streamline my workflow.In addition to technical writing, I have also used ChatGPT to help my friends improve their resumes. By inputting a few key details, such as their work experience and skills, ChatGPT can generate suggestions and ideas for improving their resume and making it more effective.Beyond technical and professional writing, ChatGPT has also been useful for coming up with ideas for my blog. As a writer, I often find myself struggling to come up with new topics to write about. However, ChatGPT can help me brainstorm ideas and come up with fresh perspectives on a wide range of subjects.Use ChatGPT as a Personal TutorOne of my favorite ways to use ChatGPT right now is to have it act as a personal tutor for me. I think this will also be especially relevant for anyone reading this blog who is interested in IT and wants to learn the skills necessary to get into IT.One way to use ChatGPT as a tutor is to have it design a study plan for you. By providing information on your course syllabus, your preferred learning style, and your schedule, ChatGPT can generate a personalized study plan that is tailored to your specific needs. This can help you focus your study time and ensure that you are covering all the material you need to know.In addition, ChatGPT can help you understand complex concepts. If you are struggling with a particular topic or subject, you can ask ChatGPT to explain it to you in a way that makes sense. By breaking down complex concepts into more easily digestible pieces of information, ChatGPT can help you grasp even the most challenging topics.Another way to use ChatGPT as a tutor is to have it design a project for you. By providing information on your interests and your course requirements, ChatGPT can generate project ideas that will help you apply your knowledge in a practical way. This can be especially useful for subjects like science and engineering, where hands-on experience is crucial.Improve Your EmployabilityAnother thing that caught me by surprise with the release of ChatGPT-3 was how good it was at impersonating popular figures. Although it is very amusing to have ChatGPT create a rap about a man clogging his toilet in the style of Eminem, we can make better use of it by making ourselves more appealing to employers.One way ChatGPT can help improve your employability is by acting as a career advisor with years of experience in your field. Simply by asking ChatGPT to provide advice on career development, you can gain valuable insights into the skills and experience required to succeed in your chosen field. You can also ask ChatGPT to review your resume and provide suggestions for improvements, helping you create a more effective and compelling document.Another way ChatGPT can help improve your employability is by creating a LinkedIn profile summary from your resume. This can save you time and effort by automating the process of creating an effective and engaging profile.You can also ask ChatGPT to help you cater your resume to specific job postings, ensuring that your skills and experience are presented in the best possible light.ConclusionMy journey with ChatGPT has been one of growing appreciation tempered with cautious optimism. While the technology is powerful and promising, it’s crucial that we approach its development and use it ethically and responsibly.The future of AI is neither a utopian dream nor a dystopian nightmare - it’s a tool whose impact will depend on how we choose to use it. As we continue to explore and develop these technologies, we must remain vigilant about their potential impacts, both positive and negative.I’m curious to hear about others’ experiences with AI tools like ChatGPT. How has it affected your work or daily life? What potential do you see, and what concerns do you have? Feel free to share your thoughts at hieu@hieuhuynh.net." }, { "title": "Tech Layoffs and You", "url": "/posts/tech-layoffs-and-you/", "categories": "Blogging, Tech", "tags": "Blogging, News, Tech, Layoffs, Career, Economy, Life", "date": "2023-02-10 07:24:00 -0800", "snippet": "IntroductionAs you might have heard, recently there has been a huge influx of layoffs and most of these layoffs have been focused on the tech industry. 93,000 jobs so far is the current count for how many people have been laid off in tech. Google cut 12,000 jobs, Amazon 18,000 jobs, Salesforce 7,000 jobs, Facebook 11,000 jobs, Twitter, 3,700 jobs, and Tesla 6,000 jobs. A lot has happened in recent years that lead up to this point but it all started with the pandemic.How We Got HereThe COVID-19 pandemic has had a significant impact on many aspects of our lives, including the economy and job market. One industry that has been particularly impacted is the tech industry. The pandemic led to a shift in consumer behavior, with many people staying at home and spending more time online. This has created new opportunities for tech companies in areas such as e-commerce, online education, and telemedicine.In combination with the massive amount of stimulus that was handed out during the lockdowns to help prop up the economy, many tech companies saw their profits soar and they were unable to keep up with demand unless they hired on more staff. Salaries saw sharp increases as competition for skilled tech workers got heated between the top tech companies.Markets were supercharged by the amount of money the government was spending on stimulus, and companies were unable to meet demand with the widespread supply chain issues so prices increased across the board and this is when we began to see inflation rear its head.As inflation started to skyrocket, the Federal Reserve felt the economy needed to dial down so that prices can go back to a normal level. One way to do this and the way that the Federal Reserve has always done this before in the past is to increase interest rates to decrease borrowing to slow down the economy.And as the interest rates continually increased the consumer uncertainty also increased causing businesses to be less willing to hire and take risks until they felt markets were stable again. This then leads to a correction for many tech companies that overhired during the pandemic. Many companies were forced to cut their labor forces to reduce cost and maintain profitability.As scary as this all sounds, this has happened many times before in the past and I can confidently say it will happen again and again in the future. Maybe not as exact of a scenario as the one we are experiencing right now but there will always be market downturns and sometimes they will even hit your specific industry the hardest.Market Crashes of the PastStock Market Crash of the 70sThe stock market crash of the 70s from 1973 to 1974 was a significant event that had lasting impact for the global economy. Out of the different events we will be discussing today this one probably has the most similarities to what we are experiencing currently.One similarity is the presence of inflation. In the 1970s, the United States experienced high levels of inflation, driven in part by the oil crisis and other economic factors. Today, inflation is again a concern, as the COVID-19 pandemic has led to supply chain disruptions and other factors that have driven up prices.The 70s also saw significant geopolitical tensions that impacted the global economy, including the Cold War and other conflicts. Today, tensions between major powers such as the US, China, and Russia are once again a concern, and their impact on the global economy remains uncertain.Due to all these factors the stock market saw a loss of 43%, nearly half of its total value and the recovery was not a great one as well. The recovery was slow and the US did not see the same level in real terms for over 20 years.Dot Com Bubble of the 2000sThe next notable market crash in our recent collective memory is the dot com bubble of the 2000s. While the current economic conditions are different from those of the dot com era, there are still several ways in which the crash continues to affect the tech industry today.One of the most significant impacts of the dot com crash was the shift in investor sentiment. During the dot com era, many investors were drawn to tech companies with little or no revenue, in the hope of making a quick profit. When the crash occurred, many of these investors lost significant amounts of money, and the tech industry lost a lot of credibility in the eyes of the broader investment community. As a result, many tech companies today face greater scrutiny and are held to higher standards than in the past.Another impact of the dot com crash was the significant drop in enrollment of computer related degrees. Confidence in the security of acquiring a tech job and living a comfortable life waned as people saw the consequences of the reckless actions taken by some of these dot com companies. 52% of dot com companies did not survive to 2004 so if you were living through this period of economic turmoil it was not unreasonable to want to choose a different career path.Housing Market Crash of 2008Finally, the most catastrophic economic event in recent years is the housing market crash of 2008. One of the most immediate impacts of the housing market crash was the wave of foreclosures that swept the country. As many homeowners found themselves unable to keep up with their mortgage payments, banks began to foreclose on their homes and sell them at reduced prices. This flood of foreclosures onto the market led to a sharp decline in home prices, which in turn made it even more difficult for homeowners to keep up with their mortgage payments. The result was a vicious cycle that saw more and more homes foreclosed on and sold at reduced prices.The plummeting home prices led to a decline in consumer spending, as homeowners cut back on spending as homeowners found themselves owing more on their mortgages than their homes were worth. The damage would then spread to the financial sector as many banks and other financial institutions had invested heavily in the housing market, and when the crash occurred, many of these institutions faced significant losses. This led to a wave of bank failures and government bailouts, as policymakers sought to stabilize the financial sector and prevent a broader economic collapse.From the market crash of the 70s to the dot com bubble to the housing market crash all these were disastrous events that destroyed the lives of millions of people and have had a lasting impact on the economy. So what do they all have in common? We recovered from every single event better and stronger than before.How We Navigate Through Tough TimesIn times of economic uncertainty, it can be challenging to stay optimistic and motivated. When the economy is struggling, it can be difficult to find employment, keep your current job, and pay bills. However, it’s important to remember that no one knows exactly what the future holds so keep a long-term perspective and remain focused on your goals.When times are tough, it can be tempting to make short-term decisions based on immediate concerns but don’t be short sighted and look at the big picture. What do you want to achieve in your career or personal life? How can you use this time to work towards those goals? How you navigate difficult times will define who you are and what your future looks like.Companies like Amazon, Ebay, and Adobe were able to survive and thrive after weathering the economic storm of the dot-com bubble crash. And companies like Google, Apple and Facebook started shortly after the bubble burst and are now some of the most successful companies in the world. The resilience of these companies demonstrates that success is still possible even during times of economic turmoil.Even in an event as catastrophic as the housing market crash, the housing market has recovered after the crash of 2008 and has even soared to new heights. These rebounds are a testament to the resilience of the broader economy as a whole so it’s important to remember that no matter how bad things seem in the short term, there is always a chance for recovery and growth. Do not be afraid to achieve your goals because of short-term turmoils.Why Choose a Tech Career During a Tech Layoff?Let me be a little more specific and share my own story. A few years ago during the pandemic I was living at home with no job, no money, and no degree. It would have been very easy for me to just say, “It is too rough out there right now. Maybe I should wait out the storm and start trying at a later time.” But I decided that during times when people are most fearful is the most important time for me to be brave. And so I decided to get a job regardless of what was happening on the news and around me and it was the best decision I had ever made.I hated the job that I got but because I hated that job it pushed me to try and pursue a career in something I enjoyed which led me to IT. If you are out there interested in IT and see all these tech layoffs and are scared to get into tech. Let me tell you this, the tech industry is not going anywhere, and you did not choose a bad career path. The investment you make today will pay dividends tomorrow and there is no better investment than in yourself.So keep studying and keep working towards your goals because the skills you learn today will carry you for the rest of your life. Even if it means taking a different path or making adjustments along the way. It’s also worth noting that the tech industry has shown remarkable resilience during economic downturns. So if you are truly passionate about tech then focus on building skills and staying relevant.During difficult times, it can be challenging to find work, so focus on building your skills and staying current with industry trends. Take an online course, start a bootcamp, do as many home labs and projects as you can, do whatever you can to sharpen your skills and stay relevant. I can not tell you how long these tough times will last but I can say with confidence that hard work and talent can not be denied for long and eventually the cream will rise to the top.“Don’t be pushed around by the fears in your mind. Be led by the dreams in your heart.”-Roy T. Bennett" }, { "title": "Let&#39;s Build a Home Server Rack", "url": "/posts/lets-build-a-home-server-rack/", "categories": "Guides, Homelab", "tags": "Instructional, Guides, Networking, Linux, VMWare, Cisco, Homelab, Server", "date": "2022-11-05 04:21:00 -0700", "snippet": "IntroductionBuilding a home server rack is a great way to expand your knowledge in network and server administration, and gain hands-on experience with enterprise-level technologies. By using Linux, VMware, and Cisco switches you can build a robust and flexible home lab environment that simulates a real-world IT infrastructure. In this guide, we will outline the steps involved in building a home server rack and provide detailed information on the hardware and software components used.Gathering the HardwareThe first step in building a home server rack is to gather the necessary hardware. You will need: A server rack: This can be a standalone rack or a cabinet that can accommodate multiple servers and switches. The size of the rack will depend on the number of servers and switches you plan to use. For a home lab, a 10U server rack should be sufficient. Servers: You can use one or multiple servers, depending on your needs. For a home lab, an Intel NUC or a small form-factor PC can work well. The servers should have sufficient RAM and storage to accommodate the virtual machines you plan to run. Switches: You can use any switch, but today we will be focusing on Cisco switches as they are the most commonly used switches in the industry and are a good place to start practicing routing and switching protocols. For a home lab, you can use Cisco Catalyst 2960. These switches are compact and have a limited number of ports, making them ideal for a home lab environment. Cables: You will need Ethernet cables to connect the switches and servers to each other, and power cables to power the servers. The cables should be of the appropriate length to reach from the servers to the switches, and from the switches to the power outlets.When building your rack and racking your servers and switches. I have a few pointers for best practices: Build your rack from the ground up: Stack your servers starting from the ground and place subsequent servers on top. Have your switches at the top of the rack. Larger servers will require two people to help rack and should be racked first. Don’t be afraid to ask for help. Know the physical dimensions of your components: Keep in mind the length and depth of your server rack. Although most racks will allow you to adjust its dimensions. You don’t want to be rebuilding an entire rack to make a two inch adjustment. Leave room to cable manage: It’s easy to want to maximize the space in your rack and not leave a lot of room in the back of your rack. But having good cable management will make it easier for you to make modifications to your rack in the future. It also allows for better ventilation for your equipment. Have cable management accessories: Cable management accessories are great for easier cable management. I would recommend a 1U cable management unit and plenty of velcro ties. I would not recommend using zip ties as they are difficult to work with when you need to make modifications.Here is an example build from my own server rack:Installing Linux and VMwareOnce you have the hardware, you can install Linux and VMware on the servers. For Linux, you can use Ubuntu or CentOS, both of which are popular distributions for server administration. You can download the ISO image of the distribution from the official website and install it on the servers using a bootable USB drive.For VMware, you can use vSphere, which is a virtualization platform that allows you to run multiple virtual machines on a single physical server. This is great if you have very few machines to work with and the same principles of provisioning and configuring physical servers apply just the same to virtual machines. You can download a trial version of vSphere from the VMware website and install it on the servers. After installation, you can configure vSphere to manage the virtual machines and allocate resources, such as RAM and storage, to each virtual machine.Configure the SwitchLet’s start by connecting to our switch either through a console connection or SSH/telnet. Next enter global configuration mode by typing:Switch&amp;gt; enableSwitch#configure terminalNow let’s configure the hostname and create a new vlan for our switch:Switch(config)#hostname homelab-switchhomelab-switch(config)#vlan 10You can give your vlan an easily recognized name like this:homelab-switch(config-vlan)#name publicNow that we have our vlan created let’s start assigning a port to the vlan:homelab-switch(config-vlan)#exithomelab-switch(config)#interface FastEthernet 0/1homelab-switch(config-if)#switchport mode accesshomelab-switch(config-if)#switchport access vlan 10If you want to assign multiple ports to a vlan at once. We would do it like so:homelab-switch(config-if)#exithomelab-switch(config)#interface range FastEthernet 0/2-10homelab-switch(config-if)#switchport mode accesshomelab-switch(config-if)#switchport access vlan 10Next let’s configure an IP address to our vlan:homelab-switch(config-vlan)#exithomelab-switch(config)#interface vlan 10homelab-switch(config-if)#ip address 10.10.0.2 255.255.255.0Finally, let’s enable inter-vlan routing and also make sure your configurations are correct:homelab-switch(config-if)#exithomelab-switch#ip routinghomelab-switch#show ip interface briefInterface IP-Address OK? Method Status ProtocolVlan10 10.10.0.2 YES manual up downCongratulations we have just configured our Cisco switch for our homelab. There is much more to configuring a switch for your network such as configuring link aggregation, spanning tree, and access control lists. But for now this is sufficient for our basic usage.Setting up virtual machines and networkingWith the servers and switches configured, it’s time to set up the virtual machines and networking. This requires a good understanding of virtualization and networking technologies.Virtual MachinesTo create virtual machines in VMware, you can use the vSphere client. It’s a graphical user interface that allows you to manage virtualized environments. Here’s a more detailed guide on how to create a virtual machine: Open the vSphere client and log in to the vCenter Server. In the vSphere Client home page, right-click on a host or cluster and select “New Virtual Machine”. Choose “Create a new virtual machine” and click “Next”. Select a name for your VM and choose where to store it. Click “Next”. Select the host or cluster where you want to run the VM and click “Next”. Choose a datastore to store the VM files and click “Next”. Select the VM compatibility and click “Next”. Usually, you’ll want to choose the latest version unless you have specific compatibility requirements. Choose the guest OS you’ll be installing. This determines default settings for the VM. Configure the virtual hardware: CPU: Select the number of virtual CPUs. Memory: Allocate RAM to the VM. Hard disk: Create a new virtual disk or use an existing one. Network: Connect the VM to a network. CD/DVD: Connect to an ISO image to install the OS. Review your settings and click “Finish” to create the VM. Once created, power on the VM and open its console. If you connected an OS installation ISO, the VM will boot from it and you can proceed with OS installation.Remember to install VMware Tools after OS installation for better performance and integration.Virtual NetworkingThe virtual networking in VMware is implemented through virtual switches. You can create virtual switches and connect them to physical switches to create virtual networks. The same principles of networking apply within virtual networks so what we did above with our real life Cisco switch we can configure the same type of network in vSphere. Here’s how you can create a virtual switch in VMware: Open the vSphere client and log in to the vCenter Server. Navigate to the host you want to create the virtual switch on. Click on the “Configure” tab and select “Networking.” Click on the “Add Networking” button and select “Virtual Switch.” Enter a name for the virtual switch and select the physical switch you want to connect it to. Configure the settings for the virtual switch, such as VLANs, security policies, and traffic shaping policies. Click on the “Finish” button to create the virtual switch.Troubleshooting and TestingAfter setting up the virtual machines and networking, it’s important to test and troubleshoot the environment. This helps to identify and resolve any issues that might arise during deployment. Here are some of the common testing and troubleshooting tasks: Ping test: Use the ping command to test connectivity between the virtual machines and the physical network. Traceroute: Use the traceroute command to determine the path taken by packets from the source to the destination. VLAN Configuration: Verify that the VLANs are configured correctly on the switches by using the show vlan command on Cisco switches. Firewall rules: Verify that the firewall rules are configured correctly on the virtual machines and switches. Router Configuration: Verify that the routing protocols, such as OSPF and BGP, are configured correctly on the routers and switches. You can use the show ip route command on Cisco routers to verify the routing information. Virtual Machine Configuration: Verify that the virtual machines are configured correctly and that they can communicate with each other and the physical network. Switch Configuration: Verify that the physical switches are configured correctly and that they are able to communicate with the virtual switches and the routers.Monitoring and MaintenanceFinally, it’s important to monitor and maintain the home server rack environment to ensure that it operates optimally. Here are some of the common monitoring and maintenance tasks: Resource Monitoring: Monitor the resources of the virtual machines, such as CPU usage, memory usage, and disk space, to ensure that they are not running out of resources. Backup and Recovery: Regularly back up the virtual machines and switches to ensure that you can recover from any failures or data loss. Software Updates: Regularly update the software on the virtual machines, switches, and routers to ensure that they are running the latest security patches and bug fixes. Virtual Machine Management: Manage the virtual machines, including creating, modifying, and deleting virtual machines, as needed.ConclusionCreating a home server rack using Linux, VMware, and Cisco technology is a great way to build a powerful and flexible computing environment. However, it requires a good understanding of virtualization, networking, and system administration technologies. By following the steps outlined in this post, you can create a home server rack yourself and learn the basics of systems administration. Having a home server rack can also come with many benefits such as having a centralized management system, improved performance, increased security, and the ability to customize the hardware and software that you use. Every home rack can be different so if you have any questions regarding your own setup, please feel free to let me know by emailing me!" }, { "title": "How to Perform a Brute Force Attack on a WiFi Network", "url": "/posts/wifi-brute-forcing-with-hashcat/", "categories": "Guides", "tags": "Instructional, Guides, Networking, Hacking, WiFi, Offensive, Hashcat", "date": "2022-07-05 04:21:00 -0700", "snippet": "IntroductionThis guide will teach you some basic penetration testing skills for wireless networks. I hope to also demonstrate how having a weak password can leave even the most secure networks vulnerable.Pre-setupTo follow along with this guide, you will need a few things to get started. First, you will need a WiFi adapter that is capable of using managed/monitor mode. If you don’t know if your adapter is capable of that, you will have to find out by searching online for your WiFi adapter’s chipset and seeing if it can utilize monitor mode.The next thing you will need will be an installation of Kali Linux. Although Kali is not the only operating system for performing these tasks, many of the tools we will be using today are already present in Kali, so it makes the process smoother. If you choose to use Kali, make sure your WiFi adapter is compatible with Kali Linux before proceeding. You can do a quick Google search to find out if your WiFi adapter is compatible with Kali.Lastly, you will need a powerful enough GPU to perform the brute forcing required to crack these hashes.Preparing our toolsIn your Kali installation, make sure your WiFi adapter is being detected by your operating system by typing in iwconfig. It should show up as so:If something similar does not show up when typing iwconfig, you might need to do some troubleshooting, like ensuring your adapter drivers are installed properly. Many times, a quick reboot will solve most issues. If it works, then we are ready to move on to the next step.Type in the following commands:sudo apt updatesudo apt upgradesudo apt install hcxdumptoolsudo apt install hcxpcapngtoolI’ve separated each command rather than combine them all into one so that we can go over what each command does. sudo apt update will update the repositories on the OS so when you make a call to install a library, it has the latest references when grabbing a download link. sudo apt upgrade will download and install any updates to all the repositories and libraries installed on your OS. sudo apt install hcxdumptool will install the first tool we will be using to capture packets. sudo apt install hcxpcapngtool will install the tool we will use to convert the packets we capture to a file that hashcat will be able to read and decrypt.Scanning for networksLet’s start by disabling our network services so we can use our network adapter to scan for networks.sudo systemctl stop NetworkManager.servicesudo systemctl stop wpa_supplicant.serviceNext, we will use the hcxdumptool we downloaded earlier to scan for networks.sudo hcxdumptool -i wlan0 -o dumpfile.pcapng --active_beacon --enable_status=15The first flag in this command -i will specify which interface we will be using to perform the scan. The -o flag will output the contents of the scan into a file. In this instance, it will be the dumpfile.pcapng file. The --active_beacon flag will transmit a beacon to every collected ESSID from the collected ESSID list every few minutes. And finally, the --enable_status=15 flag will display the following network information in the terminal: EAPOL ASSOCIATION REASSOCIATION AUTHENTICATION BEACON. You can always read more about the specific command using man hcxdumptool.Let the tool run for a few minutes and capture information. After a while, you can use the shortcut Ctrl+C to stop the scan, and now we can start cracking.Making the Hash File and Cracking ItNext, we will need to convert the newly created pcap file we just made from the scan into a format that can be processed by hashcat.sudo hcxpcapngtool -o hash.hc22000 -E essidlist dumpfile.pcapngAgain, the -o flag will output the file as hash.hc22000, and the -E flag will output the collected ESSIDs into a list. Now that we have the necessary files, we can start cracking. Remember to do this on a computer with a sufficiently powerful GPU; otherwise, it will take you hours to crack the simplest of passwords. Since we are attempting to penetrate our own network for this example, we have set the password to all digits to show the speed and efficiency at which we can crack a simple password like this.Before we can start cracking, we need to specify which network we want to crack by removing every other network we found in the last scan. Use the following command to help find the MAC address:sudo hcxdumptool --do_rcscan -i wlan0Use Ctrl-C to exit the scan. On the left side, you will see the BSSID of the network. That is what you will need to identify your network. Match it with the ESSID and write down the information before proceeding.Open up your hash.hc22000 file with a text editor; it should look something like this:WPA*02*b38d2a7c87aa0864201c41eaac3bd074*20becd364387*3420037d4435*4b6569746857696669*082b00483ffa60261b82837a38916fb92e4e0d81608343c95f2d97a978c449ed*0103007502010a00000000000000000001eb021bf76d5b9a03965527c2796825b9e268e7cdccc4f4603dce98b894613612000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001630140100000fac040100000fac040100000fac020000*02WPA*02*fdf01f941daddca2bd780d2f2a6f5711*20becd364387*3c846ae3aeb6*4b6569746857696669*72cc768ae878785bf30c22e54cc23e21362e7fbd3597d92e7bf43b88889b8ef7*0103007502010a0000000000000000fa12f4345f77049ab5a66ce61f600af4cdcf0c28104bcbbb9b17e941949249746dd2000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001630140100000fac040100000fac040100000fac020000*10WPA*02*0b4838355821f9625ca3971d6e40c934*20becd364387*3c846ae3cfcd*4b6569746857696669*72cc768ae878785bf30c22e54cc23e21362e7fbd3597d92e7bf43b88889b8ef7*0103007502010a0000000000000000fa12f852203ce4dd9ff5196d583503e10c476f203bcf5d9223ba5cecfa434910f432000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001630140100000fac040100000fac040100000fac020000*10WPA*02*9c465e97913d7c93ea37023392303428*20becd364387*6038e0edd011*4b6569746857696669*72cc768ae878785bf30c22e54cc23e21362e7fbd3597d92e7bf43b88889b8ef7*0103007502010a0000000000000000fa1225873e630b8cf46ea6eaac659603576b6dbd1e3e3640e2931ca37ce3f0b1d24d000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001630140100000fac040100000fac040100000fac020000*10Delete all the lines that do not contain your target BSSID. Save the file, and it will be what you will use to perform the attack.We will demonstrate multiple attack vectors for cracking this hash. Firstly, we will try cracking only digits:sudo hashcat -m 22000 hash.hc22000 -a 3 ?d?d?d?d?d?d?d?dThe first flag in this command, -m, will specify the hashmode to use for this attack. Since we will be cracking WPA/WPA2, we will be specifying 22000 for the mode. You can find a full list of different hashmodes here.The next flag is the -a flag and will specify the attack mode for this command execution. For this example, we will be doing a brute force attack which will iterate through every possible variation to find the right combination, so we will set the attack mode to 3. You can read more about the different attack modes here.Finally, the ?d at the end of the command specifies which character type to try when performing the attack. There are four different character types: digits, uppercase, lowercase, and special characters. The ?d denotes digits. We will try an alphanumeric attack in a later example.If you have any additional information that might help narrow down the attack, be sure to take advantage of it as it could make the difference between waiting a week for the password to get cracked to a few hours. To give an example, an offensive security expert went around sniffing for wireless passwords and was able to crack a good amount of them by only guessing ten-digit numbers because many people were using their phone numbers as their passwords. Below, we will show examples of different attack vectors and ways you can narrow your search.Different Brute Force AttacksUsing a WordlistA wordlist is a preset list of common passwords, also known as a dictionary attack. A list of common wordlists can be found in Kali under /usr/share/wordlists/ but it can also be downloaded from here.hashcat -m 22000 hash.hc22000 wordlist.txtBrute Forcing Alphanumeric and Special Character PasswordsThe following command will brute force a password with digits, lowercase, uppercase, and special characters:hashcat -m 22000 hash.hc22000 -1 ?d?l?u?s -a 3 ?1?1?1?1?1?1?1?1Rule-based AttackThis is similar to a dictionary attack, but the commands look a bit different:hashcat -m 22000 hash.hc22000 -r rules/best64.rule cracked.txt.gzThis will mutate the wordlist with the best 64 rules, which comes with the hashcat distribution. Change as necessary and remember, the time it will take the attack to finish will increase proportionally with the number of rules.Getting Your Results and ConclusionIf your attack was a success, you will find the cracked password in a .potfile, or you can type out the same cracking parameters again but tagging --show at the end.These are some of the most basic techniques a hacker can use to try to get into your network. Even if WPA/WPA2 is considered a secure way of protecting your network, it can easily be broken into if you don’t have an equally secure password as well. Over time, cracking and brute forcing methods will only get faster and more efficient, so the need for a strong password becomes increasingly necessary.As demonstrated above, it is easier to crack a sophisticated but short password than it is to crack a long but easy-to-remember password. A password containing 8 random characters like this 1S7Hd8@3 will be incredibly hard for a human to guess but incredibly easy for a computer to guess. Even a password that uses a common phrase like DrinkLots_OfWater825 will take a computer hundreds of years to guess. So in this instance, size does matter." }, { "title": "How to Run a Rust Server in Docker on AWS", "url": "/posts/rust-server-in-docker-on-aws/", "categories": "Guides", "tags": "Instructional, Guides, Cloud, AWS, Linux, Docker, Rust", "date": "2022-03-21 12:10:00 -0700", "snippet": "IntroductionThis guide will teach you how to run your own Rust server on the cloud. This guide assumes you already have some Linux knowledge and that you will be able to manage your server on your own after everything is set up. This is made for people who are not familiar with Docker or cloud services. Although we will be using AWS for this guide, the instructions here can be applied to any cloud service provider or even on your own dedicated server.What’s Docker and why Docker?Docker is a system for running services such as apps in a containerized setting. This will give you the freedom to control the resources used by your servers and will also make it easier for you to expand to multiple servers in the future if you so wish. It will also allow you to freely move your server between devices and restore from backups. If you wish to learn more about Docker and how it works, you can read more from here.Pre-setupThe only thing you will need is an AWS account. If you don’t have one yet, you can make one here.Launching a Cloud Instance Once logged into your AWS account, you can use the search bar at the top of the page and search for “EC2”. Select the first option and it will take you to the EC2 page. Click the large orange button that says “Launch instances” on the top right. Scroll down until you see “Ubuntu Server 18.04 LTS (HVM), SSD Volume Type” and select it. When selecting which CPU type it’s important to select one that can accommodate the size of your server. Since this is for demonstration purposes I will be selecting the “r5a large” type which can handle about 16 players. After selecting your CPU and memory hit next on the bottom right until you reach the “Add Storage” page. Here you change the size of your instance to 30 GiB. Now you can hit “Review and Launch” and then launch your new instance. A screen will pop up asking you if you want to “Select an existing key pair or create a new key pair”. Since this is our first time launching an instance, select “Create a new key pair”. Set whatever name you want for the key pair name. Press “Download Key Pair” and it will go to your downloads folder. You might have to wait several minutes before your instance is launched and is accessible.Installing Docker and Launching Your Rust ServerIn order to access your new instance you will need to use the key pair you created and downloaded earlier. The permissions of the private key will need to be modified so that you can use it. If you are on Linux, simply navigate to the folder where your key file is located and type the following command:chmod 400 {Private key name}.pemOn Windows you will have to modify the permissions of the file by right clicking the file then selecting properties and under the security tab hit “Advanced”. On the new window that pops up you must remove permissions from “Users”. This is how it looks on my desktop:Select “Users” and hit “Remove” then go back to your AWS instances page and look for your “Public IPv4 DNS”. It will look something like this:You will need the “Public IPv4 DNS” to connect to your instance. Once completed you can open your terminal or command prompt and navigate to the folder with your private key. Enter the following command to connect to your instance:ssh -i {Private key name}.pem ubuntu@{Public IPv4 DNS}If everything is successful you should be greeted with a “Welcome to Ubuntu 18.04.6 LTS” message in your terminal. And the first thing we will be doing is running the two following commands:apt updateapt upgradeThis will update and upgrade our repositories and repository libraries. Next we will install Docker:apt install docker.ioLet’s launch our Rust server for the first time!docker run --name rust-server didstopia/rust-serverWhat this does is, first download the latest rust-server image from Docker Hub (a public repository of Docker images), then it starts a new rust-server container, giving it the name “rust-server”. This might take a while as you are starting your server for the first time. To stop your server you can use:docker stop rust-serverTo see a full list of Docker commands you can use:docker helpConfiguring your Rust ServerFirst create your server configuration file:touch /rust.envInside the file you will need to add your environment variables. Put the following and customize where necessary:RUST_SERVER_STARTUP_ARGUMENTS=-batchmode -load +server.secure 1RUST_SERVER_IDENTITY=rustserverRUST_SERVER_SEED=12345RUST_SERVER_NAME=My Containerized Rust Server on AWS!RUST_SERVER_DESCRIPTION=I made this!RUST_RCON_PASSWORD=CHANGEMEThere are a lot more variables you can use to customize your servers. A full list can be found here. Before firing up your Rust server with your new environment variables file you must delete your old container:docker rm rust-serverNext, run the following command:docker run --name rust-server -d -p 28015:28015 -p 28015:28015/udp -p 28016:28016 -p 8080:8080 -v /rust:/steamcmd/rust --env-file /rust.env didstopia/rust-serverWe have added the -d flag, which will detach or daemonize the process, so that we won’t get regular console outputs from the server anymore.The -p flag will bind our local ports to the container ports, which will enable us to connect to the server from outside our network.The -v flag is where the magic happens, as the -v flag translates to volume. Meaning it will mount a volume on the local filesystem inside the container. The first part is the host path (/rust in this case), and the second part is the container path (/steamcmd/rust, which is always the same).Since Docker containers aren’t persistent (they can’t be permanently modified, changes aren’t saved and so on), using a volume will now store both the Rust installation data, as well as the server data (level, users, blueprints, logfiles). Storing the Rust installation data on the host system means that when the container is restarted, it won’t have to download the entire server again, but it can still update it if necessary.The --env-file flag simply loads our variables from the file we set up earlier.You should now have a full functioning, fully configured server setup. All that’s left now is to make sure it automatically restarts in case it crashes, or the host system is restarted.Automatic StartupCreate a new file in /usr/local/sbin/docker_startup.service and paste the following in it:#!/bin/bash#deletes image/usr/bin/docker rm -f rust-server 2&amp;gt;/dev/null || true#pulls and runs a new Rust server/usr/bin/docker run --name rust-server -d --restart unless-stopped -p 28015:28015 -p 28015:28015/udp -p 28016:28016 -p 28082:28082 -v /rust:/steamcmd/rust --env-file /rust.env -m 16g --cpus=&quot;2&quot; didstopia/rust-serverNote that this particular startup script uses the --rm flag, which will destroy the container once it’s stopped. This allows for clean starting/stopping of the server, as the container name will always be available this way. We’re also forcibly destroying the container both when stopping and starting the server, just in case anything goes wrong.Create another file in /etc/systemd/system/startup.service and paste the following in it:[Unit]Description=Startup ServicesAfter=multi-user.targetAfter=network-online.targetWants=network-online.target[Service]ExecStart=/usr/local/sbin/docker_startup.serviceUser=rootGroup=root[Install]WantedBy=multi-user.targetThis will create the service and will allow you stop start and stop the startup service with the following commands:service rust-server startservice rust-server stopservice rust-server statusControlling ResourcesIt’s important to control how much resource your server uses as one process overconsuming resources can end up causing other programs to crash when they hit their limit. And Rust is known to be a very resource-heavy application. Another thing is that Rust (or more accurately Unity) is known to crash when using more than 16GB of memory. Docker can solve this issue easily by adding the following flag to your docker run command: -m 16g. This will limit the maximum amount of memory your container can consume to 16GB.To limit your CPU utilization you can add the --cpus=&quot;2.0&quot; flag when running your container. The &quot;2.0&quot; in the flag represents the amount of CPUs you are allotting to that container. You can also use decimal values like --cpus=&quot;0.5&quot; or --cpus=&quot;1.5&quot;.Remember to add all Docker arguments before the image name (in this case didstopia/rust-server) otherwise they’ll get ignored.Using Custom MapsIf you wish to use a custom map for your server it is quite simple to do so. The only difference between the standard way of using a custom map and using one for your containerized Rust server, is that instead of editing your server.cfg file you will be editing your environment variables file instead. First, you will need to open your environment file, in this case rust.env and remove or comment out the RUST_SERVER_SEED= argument and the RUST_SERVER_WORLDSIZE= argument. Next, you will need to follow this guide to install the necessary dependencies and then to also obtain a direct download URL. In your environment variables file under RUST_SERVER_STARTUP_ARGUMENTS= add the following starting parameter: -levelurl &quot;{direct download link for your custom map}&quot;. For example, this is how my file looks:RUST_SERVER_STARTUP_ARGUMENTS=-batchmode -load +server.secure 1 -levelurl &quot;https://www.dropbox.com/s/cgbu3o0tngp9qgt/RedSandsCustom.map?dl=1&quot;RUST_SERVER_IDENTITY=rustserver#RUST_SERVER_SEED=12345RUST_SERVER_NAME=My Containerized Rust Server on AWS!RUST_SERVER_DESCRIPTION=I made this!RUST_RCON_PASSWORD=CHANGEMEUseful CommandsTo access the server console, we can do so with this command:docker logs -f rust-serverTo stop the server, we would run:docker stop rust-serverTo update to the latest image by pulling from Docker Hub:docker pull didstopia/rust-serverIf you get an error saying that a server with the name rust-server already exists, we can remove the container by running:docker rm -f rust-serverTo send an RCON command to your server, you can use the following:docker exec rust-server rcon {command}To monitor your resource usage for each container:docker statsTo change an existing container’s environment variables you will have to edit the following file:vim /var/lib/docker/containers/{container-id}/config.jsonYou can find the container-id by executing the following command:docker inspect [container-name] | grep &quot;Id&quot;Final NotesI am still learning the Linux ecosystem and Docker so I will continually update this guide as I find better ways to launch and manage applications. If you find anything I’ve said here to be erroneous or if there is a better way to do things, feel free to contact me and let me know! I would love to hear any type of feedback." } ]
